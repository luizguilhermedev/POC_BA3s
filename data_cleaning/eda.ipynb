{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and Data cleaning - A3Data challenge\n",
    "\n",
    "- Exploratory data analysis\n",
    "- Data-cleaning\n",
    "- Pipeline to automate Data-cleaning\n",
    "    - ETL books_data\n",
    "    - ETL books_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_books_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(f'Descriprion:\\n{data.describe()}')\n",
    "    print(f'\\n\\nMissing values: \\n{data.isnull().sum()}')\n",
    "\n",
    "\n",
    "    data = data.drop(['previewLink', 'infoLink'], axis=1)\n",
    "    data = data.drop(['image'], axis=1)\n",
    "\n",
    "    data.columns = data.columns.str.lower()\n",
    "\n",
    "    data = data.fillna({\n",
    "    'description': 'Description not available',\n",
    "    'authors': \"['Author not informed or not available']\",\n",
    "    'image': 'Image not available for this book',\n",
    "    'previewlink': 'Preview link not available',\n",
    "    'publisher':'Publisher not informed',\n",
    "    'publisheddate': 'Date not informed',\n",
    "    'infoLink': 'Info link not available',\n",
    "    'categories': \"['Category not informed']\",\n",
    "    'title': 'Title not informed for this book',\n",
    "    'ratingscount': data['ratingscount'].median(),\n",
    "})\n",
    "    \n",
    "    print(f'\\n\\nMissing Values now: \\n{data.isnull().sum()}')\n",
    "\n",
    "    # Show only the year of published date\n",
    "    data['publisheddate'] = data['publisheddate'].str[:4]\n",
    "\n",
    "\n",
    "    # remove [] from categories and author\n",
    "    data['categories'] = data['categories'].str.replace('[', ' ')\n",
    "    data['categories'] = data['categories'].str.replace(']', ' ')\n",
    "    data['authors'] = data['authors'].str.replace('[', ' ')\n",
    "    data['authors'] = data['authors'].str.replace(']', ' ')\n",
    "    data['authors'] = data['authors'].str.replace(\"'\", ' ')\n",
    "    data['categories'] = data['categories'].str.replace(\"'\", ' ')\n",
    "    data['categories'] = data['categories'].str.replace(\",\", ' ')\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    data = data.rename(columns={\n",
    "    'categories': 'book_gender'\n",
    "})\n",
    "    # All columns to lowercase\n",
    "    data.columns = data.columns.str.lower()\n",
    "    \n",
    "    #save to data_cleaned folder\n",
    "\n",
    "    new_data = data.to_csv('data_cleaned/books_data_cleaned.csv', index=False)\n",
    "\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_books_rating(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(f'Descriprion:\\n{data.describe()}')\n",
    "    print(f'\\n\\nMissing values: \\n{data.isnull().sum()}')\n",
    "\n",
    "    data = data.drop(['Id'], axis=1)\n",
    "    data = data.drop(['User_id'], axis=1)\n",
    "\n",
    "    data.columns = data.columns.str.lower()\n",
    "    data = data.rename(columns={\n",
    "        'text': 'review',\n",
    "        'score': 'rating',\n",
    "    })\n",
    "\n",
    "    data = data.fillna({\n",
    "        'price': data['price'].median(),\n",
    "        'rating': data['rating'].median(),\n",
    "        'title': 'Title not informed',\n",
    "        'profilename': 'Profile name not informed',\n",
    "        'summary': 'Summary not informed for this book',\n",
    "        'review': 'Review not informed',\n",
    "    })\n",
    "\n",
    "    data['rating'] = data['rating'].round(2)\n",
    "\n",
    "    new_data = data.to_csv('data_cleaned/books_rating_cleaned.csv', index=False)    \n",
    "\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriprion:\n",
      "               Price         score          time\n",
      "count  481171.000000  3.000000e+06  3.000000e+06\n",
      "mean       21.762656  4.215289e+00  1.132307e+09\n",
      "std        26.206541  1.203054e+00  1.493202e+08\n",
      "min         1.000000  1.000000e+00 -1.000000e+00\n",
      "25%        10.780000  4.000000e+00  9.999072e+08\n",
      "50%        14.930000  5.000000e+00  1.128298e+09\n",
      "75%        23.950000  5.000000e+00  1.269130e+09\n",
      "max       995.000000  5.000000e+00  1.362355e+09\n",
      "\n",
      "\n",
      "Missing values: \n",
      "Id                   0\n",
      "Title              208\n",
      "Price          2518829\n",
      "User_id         561787\n",
      "profileName     561905\n",
      "score                0\n",
      "time                 0\n",
      "summary            407\n",
      "text                 8\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "etl_books_rating('Books_rating.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriprion:\n",
      "               Price         score          time\n",
      "count  481171.000000  3.000000e+06  3.000000e+06\n",
      "mean       21.762656  4.215289e+00  1.132307e+09\n",
      "std        26.206541  1.203054e+00  1.493202e+08\n",
      "min         1.000000  1.000000e+00 -1.000000e+00\n",
      "25%        10.780000  4.000000e+00  9.999072e+08\n",
      "50%        14.930000  5.000000e+00  1.128298e+09\n",
      "75%        23.950000  5.000000e+00  1.269130e+09\n",
      "max       995.000000  5.000000e+00  1.362355e+09\n",
      "\n",
      "\n",
      "Missing values: \n",
      "Id                   0\n",
      "Title              208\n",
      "Price          2518829\n",
      "User_id         561787\n",
      "profileName     561905\n",
      "score                0\n",
      "time                 0\n",
      "summary            407\n",
      "text                 8\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing Values now: \n",
      "title          0\n",
      "price          0\n",
      "profilename    0\n",
      "score          0\n",
      "time           0\n",
      "summary        0\n",
      "review         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# generate a function to load and transform the rating data\n",
    "\n",
    "def etl_books_rating(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(f'Descriprion:\\n{data.describe()}')\n",
    "    print(f'\\n\\nMissing values: \\n{data.isnull().sum()}')\n",
    "\n",
    "    data = data.drop(['Id'], axis=1)\n",
    "    data = data.drop(['User_id'], axis=1)\n",
    "\n",
    "    data.columns = data.columns.str.lower()\n",
    "\n",
    "    data = data.fillna({\n",
    "    'title': 'Title not informed',\n",
    "    'price': data['price'].median(),\n",
    "    'profilename': 'profilename not informed',\n",
    "    'summary': 'Description not available',\n",
    "    'text': 'Review not available',\n",
    "})\n",
    "    \n",
    "    data = data.rename(columns={\n",
    "    'text': 'review'\n",
    "})\n",
    "    \n",
    "    data['score'] = data['score'].round(2)\n",
    "\n",
    "    print(f'\\n\\nMissing Values now: \\n{data.isnull().sum()}')\n",
    "\n",
    "    new_data = data.to_csv('data_cleaned/books_rating_cleaned.csv', index=False)\n",
    "\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>profilename</th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "      <th>summary</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Its Only Art If Its Well Hung!</td>\n",
       "      <td>14.93</td>\n",
       "      <td>Jim of Oz \"jim-of-oz\"</td>\n",
       "      <td>4.0</td>\n",
       "      <td>940636800</td>\n",
       "      <td>Nice collection of Julie Strain images</td>\n",
       "      <td>This is only for Julie Strain fans. It's a col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>14.93</td>\n",
       "      <td>Kevin Killian</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1095724800</td>\n",
       "      <td>Really Enjoyed It</td>\n",
       "      <td>I don't care much for Dr. Seuss but after read...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>14.93</td>\n",
       "      <td>John Granger</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1078790400</td>\n",
       "      <td>Essential for every personal and Public Library</td>\n",
       "      <td>If people become the books they read and if \"t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>14.93</td>\n",
       "      <td>Roy E. Perry \"amateur philosopher\"</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1090713600</td>\n",
       "      <td>Phlip Nel gives silly Seuss a serious treatment</td>\n",
       "      <td>Theodore Seuss Geisel (1904-1991), aka &amp;quot;D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dr. Seuss: American Icon</td>\n",
       "      <td>14.93</td>\n",
       "      <td>D. H. Richards \"ninthwavestore\"</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1107993600</td>\n",
       "      <td>Good academic overview</td>\n",
       "      <td>Philip Nel - Dr. Seuss: American IconThis is b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            title  price                         profilename  \\\n",
       "0  Its Only Art If Its Well Hung!  14.93               Jim of Oz \"jim-of-oz\"   \n",
       "1        Dr. Seuss: American Icon  14.93                       Kevin Killian   \n",
       "2        Dr. Seuss: American Icon  14.93                        John Granger   \n",
       "3        Dr. Seuss: American Icon  14.93  Roy E. Perry \"amateur philosopher\"   \n",
       "4        Dr. Seuss: American Icon  14.93     D. H. Richards \"ninthwavestore\"   \n",
       "\n",
       "   rating        time                                          summary  \\\n",
       "0     4.0   940636800           Nice collection of Julie Strain images   \n",
       "1     5.0  1095724800                                Really Enjoyed It   \n",
       "2     5.0  1078790400  Essential for every personal and Public Library   \n",
       "3     4.0  1090713600  Phlip Nel gives silly Seuss a serious treatment   \n",
       "4     4.0  1107993600                           Good academic overview   \n",
       "\n",
       "                                              review  \n",
       "0  This is only for Julie Strain fans. It's a col...  \n",
       "1  I don't care much for Dr. Seuss but after read...  \n",
       "2  If people become the books they read and if \"t...  \n",
       "3  Theodore Seuss Geisel (1904-1991), aka &quot;D...  \n",
       "4  Philip Nel - Dr. Seuss: American IconThis is b...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_cleaned/books_rating_cleaned.csv')\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "price          0\n",
       "profilename    0\n",
       "rating         0\n",
       "time           0\n",
       "summary        0\n",
       "review         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
