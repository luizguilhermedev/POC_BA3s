{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and Data cleaning - A3Data challenge\n",
    "\n",
    "- Exploratory data analysis\n",
    "- Data-cleaning\n",
    "- Pipeline to automate Data-cleaning\n",
    "    - ETL books_data\n",
    "    - ETL books_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_books_data(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(f'Descriprion:\\n{data.describe()}')\n",
    "    print(f'\\n\\nMissing values: \\n{data.isnull().sum()}')\n",
    "\n",
    "\n",
    "    data = data.drop(['previewLink', 'infoLink'], axis=1)\n",
    "    data = data.drop(['image'], axis=1)\n",
    "\n",
    "    data.columns = data.columns.str.lower()\n",
    "\n",
    "    data = data.fillna({\n",
    "    'description': 'Description not available',\n",
    "    'authors': \"['Author not informed or not available']\",\n",
    "    'image': 'Image not available for this book',\n",
    "    'previewlink': 'Preview link not available',\n",
    "    'publisher':'Publisher not informed',\n",
    "    'publisheddate': 'Date not informed',\n",
    "    'infoLink': 'Info link not available',\n",
    "    'categories': \"['Category not informed']\",\n",
    "    'title': 'Title not informed for this book',\n",
    "    'ratingscount': data['ratingscount'].median(),\n",
    "})\n",
    "    \n",
    "    print(f'\\n\\nMissing Values now: \\n{data.isnull().sum()}')\n",
    "\n",
    "    # Show only the year of published date\n",
    "    data['publisheddate'] = data['publisheddate'].str[:4]\n",
    "\n",
    "\n",
    "    # remove [] from categories and author\n",
    "    data['categories'] = data['categories'].str.replace('[', ' ')\n",
    "    data['categories'] = data['categories'].str.replace(']', ' ')\n",
    "    data['authors'] = data['authors'].str.replace('[', ' ')\n",
    "    data['authors'] = data['authors'].str.replace(']', ' ')\n",
    "    data['authors'] = data['authors'].str.replace(\"'\", ' ')\n",
    "    data['categories'] = data['categories'].str.replace(\"'\", ' ')\n",
    "    data['categories'] = data['categories'].str.replace(\",\", ' ')\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    data = data.rename(columns={\n",
    "    'categories': 'book_gender'\n",
    "})\n",
    "    # All columns to lowercase\n",
    "    data.columns = data.columns.str.lower()\n",
    "    \n",
    "    #save to data_cleaned folder\n",
    "\n",
    "    new_data = data.to_csv('data_cleaned/books_data_cleaned.csv', index=False)\n",
    "\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_books_rating(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(f'Descriprion:\\n{data.describe()}')\n",
    "    print(f'\\n\\nMissing values: \\n{data.isnull().sum()}')\n",
    "\n",
    "    data = data.drop(['Id'], axis=1)\n",
    "    data = data.drop(['User_id'], axis=1)\n",
    "\n",
    "    data.columns = data.columns.str.lower()\n",
    "    data = data.rename(columns={\n",
    "        'text': 'review',\n",
    "        'score': 'rating',\n",
    "    })\n",
    "\n",
    "    data = data.fillna({\n",
    "        'price': data['price'].median(),\n",
    "        'profilename': 'Profile name not informed',\n",
    "        'review': 'Review not informed',\n",
    "    })\n",
    "\n",
    "    data['rating'] = data['rating'].round(2)\n",
    "\n",
    "    new_data = data.to_csv('data_cleaned/books_rating_cleaned.csv', index=False)    \n",
    "\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriprion:\n",
      "               Price         score          time\n",
      "count  481171.000000  3.000000e+06  3.000000e+06\n",
      "mean       21.762656  4.215289e+00  1.132307e+09\n",
      "std        26.206541  1.203054e+00  1.493202e+08\n",
      "min         1.000000  1.000000e+00 -1.000000e+00\n",
      "25%        10.780000  4.000000e+00  9.999072e+08\n",
      "50%        14.930000  5.000000e+00  1.128298e+09\n",
      "75%        23.950000  5.000000e+00  1.269130e+09\n",
      "max       995.000000  5.000000e+00  1.362355e+09\n",
      "\n",
      "\n",
      "Missing values: \n",
      "Id                   0\n",
      "Title              208\n",
      "Price          2518829\n",
      "User_id         561787\n",
      "profileName     561905\n",
      "score                0\n",
      "time                 0\n",
      "summary            407\n",
      "text                 8\n",
      "dtype: int64\n",
      "\n",
      "\n",
      "Missing Values now: \n",
      "title          0\n",
      "price          0\n",
      "profilename    0\n",
      "score          0\n",
      "time           0\n",
      "summary        0\n",
      "review         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# generate a function to load and transform the rating data\n",
    "\n",
    "def etl_books_rating(file_path):\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(f'Descriprion:\\n{data.describe()}')\n",
    "    print(f'\\n\\nMissing values: \\n{data.isnull().sum()}')\n",
    "\n",
    "    data = data.drop(['Id'], axis=1)\n",
    "    data = data.drop(['User_id'], axis=1)\n",
    "\n",
    "    data.columns = data.columns.str.lower()\n",
    "\n",
    "    data = data.fillna({\n",
    "    'title': 'Title not informed',\n",
    "    'price': data['price'].median(),\n",
    "    'profilename': 'profilename not informed',\n",
    "    'summary': 'Description not available',\n",
    "    'text': 'Review not available',\n",
    "})\n",
    "    \n",
    "    data = data.rename(columns={\n",
    "    'text': 'review'\n",
    "})\n",
    "    \n",
    "    data['score'] = data['score'].round(2)\n",
    "\n",
    "    print(f'\\n\\nMissing Values now: \\n{data.isnull().sum()}')\n",
    "\n",
    "    new_data = data.to_csv('data_cleaned/books_rating_cleaned.csv', index=False)\n",
    "\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
